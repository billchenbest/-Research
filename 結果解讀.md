### Step1「好/壞資料」特徵辨識：結果解讀（`step1_fail_feature_run_20260104_221043`）

這份說明是針對資料夾 `step1_fail_feature_run_20260104_221043/step1_fail_feature_analysis/` 內的輸出，協助你理解：
- **哪些資料比較容易 Step1 不通過（Fail）**
- **哪些特徵最能區分好/壞**
- **怎麼讀「樹狀規則」與各個輸出檔**

---

### 1) 先講清楚：什麼叫 Pass / Fail？

- **Fail 定義**：同一列資料只要 `J分數(差分)(Euc)` 或 `J分數(差分)(Cos)` **任一個** \( \le \) 你設定的門檻（GUI 裡的「Fail 門檻」），就標記為 **Fail**。
- **Pass 定義**：上述條件都不成立，才是 **Pass**。

> 備註：這個 `step1_fail_feature_analysis` 資料夾內的檔案本身**不會記錄當時的門檻數字**（例如 0.85 或 0.7），門檻是你執行時在 GUI 輸入的值。

---

### 2) 本次跑出來的整體統計（看 `metrics.txt`）

你這次的 Step1 分析總共有 **60** 筆資料，其中：
- **Fail：12 筆（fail_rate=0.200）**
- **Pass：48 筆（pass_rate=0.800）**

依測試來源（Source）分開看（也在 `metrics.txt`）：
- **Source=C（測試組A / Severity）**：36 筆，Fail 5 筆（**13.9%**）
- **Source=D（測試組B / L變化）**：12 筆，Fail 5 筆（**41.7%**）← **最容易失敗**
- **Source=E（測試組C / I變化）**：12 筆，Fail 2 筆（**16.7%**）

---

### 3) 你最需要看的檔案：`decision_tree_rules.txt`（樹狀規則）

這份檔案就是「用樹狀規則把資料切成幾群」，每一群都有一個 **fail_rate**，用來表示：
- **這一群資料裡，有多少比例會 Fail**

你的樹狀規則（重點整理）如下（括號為該群大小與 fail_rate）：

- **第一刀最關鍵的特徵是 `L3_over_I`（約等於 \(L^3 / I\)）**
  - **如果 `L3_over_I <= 1.18276e+06`**（n=24，fail_rate=0.333）
    - 再看 **`L長度(m)`**
      - **`L長度(m) <= 39.375`** → **高風險群**（n=12，**fail_rate=0.417**）
      - **`L長度(m) > 39.375`** → 中風險（n=12，fail_rate=0.250）
  - **如果 `L3_over_I > 1.18276e+06`**（n=36，fail_rate=0.111）
    - 再看 **`I(m^4)`**
      - **`I(m^4) <= 0.0190879`** → 低風險（n=20，fail_rate=0.150）
      - **`I(m^4) > 0.0190879`** → **最穩定群**（n=16，**fail_rate=0.062**）

#### 3.1 這些規則在工程上怎麼理解？

- **`L3_over_I` 小 → 容易 Fail**  
  直覺上可解讀為「相對幾何剛度/尺度組合較不利」（這裡先把它當成幾何組合指標即可）。
- **在 `L3_over_I` 已經偏小的情況下，如果 `L` 又更小（<=39.375）→ fail_rate 最高（41.7%）**
- **`L3_over_I` 偏大且 `I` 偏大 → fail_rate 最低（6.2%）**  
  代表這類幾何組合在 Step1 更容易通過。

---

### 4) 「哪些特徵最重要？」看 `feature_importance.csv`

你這次只有 3 個特徵被樹用到（也就是它真的拿來切分的）：
- **`L3_over_I`**（最重要）
- **`L長度(m)`**
- **`I(m^4)`**

這份 `importance` 是用「每次切分帶來的 impurity reduction」加總而來，數值越大代表越能分開 Fail/Pass。

---

### 5) 用分箱表快速驗證：看 `fail_rate_by_feature_csv/`

這個資料夾是一堆 CSV（每個特徵一個檔），它做的是「把特徵分成 4 個區間」然後計算每個區間的 fail_rate，讓你肉眼確認趨勢。

你這次最值得看的幾個（因為跟樹規則一致）：
- **`NUM_L3_over_I.csv`**
  - 最低那一段的 fail_rate **0.333**（24 筆中 8 筆 Fail）→ 對應樹的第一刀高風險方向
- **`NUM_L長度(m).csv`**
  - `L` 偏大的那一段 fail_rate **0.300**（20 筆中 6 筆 Fail）→ 這個分箱跟樹的門檻（39.375）不完全同一刀，但仍顯示 `L` 對 Fail 有影響
- **`NUM_I(m^4).csv`**
  - `I` 較大那一段 fail_rate **0.300**（20 筆中 6 筆 Fail）→ 分箱只是粗略視角；樹的切點是 0.0190879，且「I 大」那一支在 `L3_over_I` 大的條件下反而是**更低 fail_rate（0.062）**

> 重點：分箱表是「單一特徵的粗略視角」，樹是「多特徵組合後」的更精準分群，所以以樹規則為主。

---

### 6) 為什麼 `metrics.txt` 會顯示 TP=0？（你可能覺得怪）

`metrics.txt` 裡的混淆矩陣顯示：
- TP=0、TN=48、FN=12（看起來像「全部都預測 Pass」）

原因是：目前分類器的預測規則是 **leaf 的 fail_rate >= 0.5 才預測 Fail**。  
而你這棵樹的各個 leaf fail_rate 最高只有 **0.417**，所以在「以 0.5 為界」時，模型會全部判成 Pass。

但這不代表分析沒用：  
這棵樹的核心用途是「**把資料分群 + 告訴你哪一群 fail_rate 高**」（高風險/低風險），用於解釋與找特徵。

如果你想要它真的能「分類抓出 Fail」，下一步可以做：
- **把判定閾值改成較低**（例如 leaf fail_rate >= 0.25 就當 Fail）
- 或 **讓樹更容易切出高 fail 群**（例如降低 `min_leaf`、或加深 `max_depth`，但規則會變複雜、也更可能過擬合）

---

### 7) 最快的結論（本次資料）

- **最容易 Fail 的群**：`L3_over_I` 偏小且 `L <= 39.375`（fail_rate=0.417）
- **最穩定的群**：`L3_over_I` 偏大且 `I > 0.0190879`（fail_rate=0.062）
- **Source=D（L變化）** 是你這次 Step1 最容易出問題的來源（fail_rate=0.417）

---

### 8) 你接下來可以怎麼用（建議）

- **論文呈現**：直接引用 `decision_tree_rules.txt` 的規則 + 本檔第 7 節的摘要
- **工程調參**：針對「高風險群」的幾何組合，觀察是否需要：
  - 調整 Step1 的門檻（Fail 門檻）
  - 或把這些群優先送去 Step2/Step3 做更細的判別


